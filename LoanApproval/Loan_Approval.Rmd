---
title: "Loan Approval"
author: "Isac Artzi"
date: "12/23/2020"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Loan Approval data setup

This example demonstrates the use of **Logistic Regression** to predict the likelihood of a loan to be approved. Data source is synthetic, created for this project

```{r get_data}

loan.df <- read.csv("LoanApproval.csv")
head(loan.df)

# Check for missing values
sum(is.na(loan.df))
```

```{r data_exploration}

summary(loan.df)

```

## Partition Data

Split the data into a **training set** and **testing set**

```{r partition}
set.seed(2)
# Split the data 80:20
train.sample <- sample(c(1:dim(loan.df)[1]), dim(loan.df)[1]*0.8)

train.df <- loan.df[train.sample,]
test.df <- loan.df[-train.sample,]
```

## Run the Logistic regression model

Using the glm() function

```{r run_logistic_reg}

logit.reg <- glm(Approval ~ ., train.df, family="binomial")
options(scipen = 999)
summary(logit.reg)
```

## Use Odds to interpret results

For example: one unit of income increases the chances of approval by 0.000008892

## Evaluate model performance

Using predict() to compute predicted probabilities and compare predicted vs actual

```{r evaluate_performance}

logit.reg.pred <- predict(logit.reg, test.df[,-7], type="response")

# Compare first 20 actual vs predicted values

data.frame(actual = test.df$Approval[1:20], predicted = logit.reg.pred[1:20])
```

## Model validation

Plot  **Lift** and **Gain** charts

```{r validation}
library(gains)

gain <- gains(test.df$Approval, logit.reg.pred, groups=length(logit.reg.pred))

# plot Lift chart

plot(c(0, gain$cume.pct.of.total*sum(test.df$Approval))~c(0,gain$cume.obs), xlab="# records", ylab = "Cumulative Gain", main="Gain and Lift Chart", type="l", col="blue")

lines(c(0, sum(test.df$Approval))~c(0, dim(test.df)[1]), col="red", 
      legend("topleft",c("With prediction","No Prediction"),fill=c("blue","red")))
```

### Additional Validation

Verify the assumption of non-multicollinearity

```{r test_multicollinearity}
library(car)
vif(logit.reg)

```
## Alternative (simpler) model

After removing multicollinear variables

```{r run_logistic_reg_simplified}

theFormula = Approval ~ Term + Income + FICO
logit.reg <- glm(formula = theFormula, train.df, family="binomial")
options(scipen = 999)
summary(logit.reg)
```

## Evaluate simplified model performance

Using predict() to compute predicted probabilities and compare predicted vs actual in the simplified model

```{r evaluate_simplified_performance}

logit.reg.pred <- predict(logit.reg, test.df[,-7], type="response")

# Compare first 20 actual vs predicted values

data.frame(actual = test.df$Approval[1:20], predicted = logit.reg.pred[1:20])
```

## Simplified Model validation

Plot a **Lift** chart

```{r simplified_validation}
library(gains)

gain <- gains(test.df$Approval, logit.reg.pred, groups=length(logit.reg.pred))

# plot Lift chart


plot(c(0, gain$cume.pct.of.total*sum(test.df$Approval))~c(0,gain$cume.obs), xlab="# records", ylab = "Cumulative Gain", main="Gain and Lift Chart", type="l", col="blue")

lines(c(0, sum(test.df$Approval))~c(0, dim(test.df)[1]), col="red", 
      legend("topleft",c("With prediction","No Prediction"),fill=c("blue","red")))
```

### Re-validate

Re-test multicollinearity

```{r re_test_multicollinearity}
library(car)
vif(logit.reg)
```

### Make Predictions

Make predictions using the previously sampled test data

```{r make_prediction}

logit.reg.prob <- predict(logit.reg, test.df, type="response" )
logit.reg.prob.df <- data.frame(logit.reg.prob)

# Extract only decisions made with a probability higher than 80%
approvals <- ifelse(logit.reg.prob.df > 0.8, 1, 0)
head(approvals, 20)
```

### Prediction Validation

Use a confusion matrix to measure the extent of misclassification. Then, further analyze measures like *Sensitivity* and *Specificity*

```{r confusion}
table(test.df$Approval, approvals)
classification.error <- mean(approvals != test.df$Approval)
classification.error

accuracy <- 1 - classification.error
accuracy

## Presition and reacll

## Impot Library
library(caret)

test.df$Approval <- factor(test.df$Approval)
approvals <- factor(approvals)

#create a confution matrix  
conf_matrix <- confusionMatrix(test.df$Approval, approvals)



# Rename the columns
colnames(conf_matrix_df) <- c("predicted_no", "predicted_yes")
## add prestion and reacall into this model based on the coffmax 

# Create the plot
library(ggplot2)
ggplot(conf_matrix_df, aes(x = Var1, y = Var2)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  scale_fill_gradient(low = "white", high = "steelblue") +
  ggtitle("Confusion Matrix") +
  xlab("Predicted") +
  ylab("Actual")

```
### Plot AUC and ROC curves

```{r auc_roc}
library(ROCR)

prob <- predict(logit.reg, newdata = test.df, type="response")
pred <- prediction(prob, test.df$Approval)

# Plot True Positive Rate (tpr) vs False Positive Rate (fpr)
pmf <- performance(pred, measure="tpr", xmeasure="fpr")
plot(pmf, col="red")

auc <- performance(pred, measure="auc")
auc <- auc@y.values[[1]]
auc
```
